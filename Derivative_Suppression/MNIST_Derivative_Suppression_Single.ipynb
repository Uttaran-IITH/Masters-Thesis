{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T05:46:14.039163Z",
     "start_time": "2019-06-22T05:45:57.868396Z"
    },
    "scrolled": true
   },
   "source": [
    "Load required packages (Keras, tensotflow-gpu, numpy, opencv-python, matplotlib (for plotting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:51:33.306351Z",
     "start_time": "2019-06-22T07:51:33.299877Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import Structural_Perturbations as SP\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T14:57:54.883474Z",
     "start_time": "2019-02-28T14:57:54.369538Z"
    }
   },
   "source": [
    "Load Dataset, specify hyperparameters such as batch_size, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:51:34.168278Z",
     "start_time": "2019-06-22T07:51:33.706221Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\"\"\"Specifies batch size, number of classes in data and number of epochs\"\"\"\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "\"\"\"input image dimensions\"\"\" \n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\"\"\"Load/Download Dataset\"\"\"\n",
    "from keras.datasets import mnist\n",
    "train_data,train_labels,eval_data,eval_labels = SP.load('mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T14:57:55.097717Z",
     "start_time": "2019-02-28T14:57:55.049677Z"
    }
   },
   "source": [
    "Defines model architecture, model evaluation function, training function, derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:51:34.229647Z",
     "start_time": "2019-06-22T07:51:34.210380Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Defines architecture of the model. We use a 2 conv-layer followed by a fully-connected layer with \n",
    "   max-pooling and dropout in between layers. Loss is categorical cross-entropy and optimiser used is Adam\"\"\"\n",
    "def new_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            32, kernel_size=(3, 3), activation='relu',\n",
    "            input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"Evaluates a given model over a range of perturbation\n",
    "   Local Variables : \n",
    "   \n",
    "   res : stores the perturbation and accuracy of the model on that pertubation\n",
    "   df : stores the values of the derivative of the accuracy vs perturbation array\n",
    "   model : the loaded model\n",
    "   base : baseline accuracy of the model\n",
    "   name : name of the perturbation\n",
    "   alpha : the array of perturbation to check\n",
    "   d : the original unperturbed dataset\"\"\"\n",
    "def evaluate(model, base, d, name, alpha):\n",
    "    global epsilon\n",
    "    print(\"Evaluating\", alpha)\n",
    "    res = []\n",
    "    for i in alpha:\n",
    "        data = np.copy(d)\n",
    "        data = SP.Transform(name, data, i)\n",
    "        labels = data[:, -1]\n",
    "        labels = keras.utils.to_categorical(labels, 10)\n",
    "        data = data[:, 0:784]\n",
    "        data = data.reshape(-1, 28, 28, 1)\n",
    "        m1 = model.evaluate(\n",
    "            data, labels, verbose=0, batch_size=2048)[1]\n",
    "        res.append([i, m1])\n",
    "    res = np.array(res)\n",
    "    \n",
    "    '''Check if the lowest model accuracy is below threshold. If yes find the largest change, calculate if accuracy\n",
    "        at that point is below threshold and return the perturbation(i). If no, return out of range perturbation to quit'''\n",
    "    \n",
    "    if base - min(res[:, 1]) > epsilon:\n",
    "        res = np.array(res)\n",
    "        res = res[np.lexsort(np.fliplr(res).T)]\n",
    "        df = derivative(res)\n",
    "        for k in range(1, df[:, 1].shape[0]):\n",
    "            i = df[:, 0][np.where(df[:, 1] == np.sort(df[:, 1])[-k])][0]\n",
    "            if (base - res[:, 1][np.where(res[:, 0] == i)][0]) > epsilon:\n",
    "#                 print(\"Accuracy at \", i, \" = \",\n",
    "#                       res[:, 1][np.where(res[:, 0] == i)])\n",
    "                break\n",
    "#         \"\"\"Plot the derivative values\"\"\"\n",
    "#         plt.plot(df[:, 0], df[:, 1])\n",
    "#         plt.axvline(i)\n",
    "#         df = df[np.lexsort(np.fliplr(df).T)]\n",
    "#         plt.show()\n",
    "        return i, res\n",
    "    else:\n",
    "        return max(alpha)+1, res\n",
    "\n",
    "\"\"\"Perturbs training dataset symmetrically and trains a given model on a perturbed dataset. Returns model\"\"\"\n",
    "def train_model(name, d, alpha):\n",
    "    data = np.copy(d)\n",
    "    if name == 'Perspective':\n",
    "        alpha.append(56-alpha[-1])\n",
    "    elif name == \"Scaling\":\n",
    "        alpha.append(2-alpha[-1])\n",
    "    else:\n",
    "        alpha.append(-alpha[-1])\n",
    "    print(\"To be trained on \", alpha)\n",
    "    for i in alpha:\n",
    "        if i != alpha[0]:\n",
    "            perturbed_data = SP.Transform(name, d, i)\n",
    "            data = np.concatenate((data, perturbed_data))\n",
    "    model = new_model()\n",
    "    labels = data[:, -1]\n",
    "    labels = keras.utils.to_categorical(labels, 10)\n",
    "    data = data[:, 0:784].reshape(-1, 28, 28, 1)\n",
    "    model.fit(data, labels, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "    return model\n",
    "\n",
    "\"\"\"Loads data and stacks the labels as a column of data. This is required for multiprocessing.\"\"\"\n",
    "def load_data():\n",
    "    train_data, train_labels, eval_data, eval_labels = SP.load('mnist')\n",
    "    train_data = train_data.reshape(-1, 784)\n",
    "    train_labels = train_labels.reshape(-1, 1)\n",
    "    train = np.hstack((train_data, train_labels))\n",
    "    eval_data = eval_data.reshape(-1, 784)\n",
    "    eval_labels = eval_labels.reshape(-1, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    test = np.hstack((eval_data, eval_labels))\n",
    "    return (train, test, input_shape)\n",
    "\n",
    "\"\"\"Return the derivative array\"\"\"\n",
    "def derivative(res, width=1):\n",
    "    res = np.array(res)\n",
    "    res = res[np.lexsort(np.fliplr(res).T)]\n",
    "    a = []\n",
    "    for i in range(res.shape[0] - 1):\n",
    "        a.append([res[:, 0][i], np.abs(res[:, 1][i + 1] - res[:, 1][i])])\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:51:36.766228Z",
     "start_time": "2019-06-22T07:51:34.553563Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Loads the data and Vanilla model\"\"\"\n",
    "train,test,input_shape = load_data()\n",
    "model = load_model(\"../../MNIST/MNIST_vanilla.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:51:41.617337Z",
     "start_time": "2019-06-22T07:51:36.840231Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Finds the baseline accuracy of the vanilla model.\n",
    "   Variables:\n",
    "   \n",
    "   res : Stores the results array of accurcy vs perturbation\n",
    "   \n",
    "   points : Initialize with initial (natural) pertubation.\n",
    "            Scaling : 1\n",
    "            Perspective : 28\n",
    "            Else : 0\n",
    "            Stores the points on which derivative was maximum and hence needs training.\n",
    "            \n",
    "   epsilon : Defines our threshold. 0.1 = 10% accuracy drop\n",
    "   \n",
    "   max_perturbation : Stores the maximum allowed perturbation\n",
    "   \n",
    "   name : Name of pertubration {Exposure, Scaling, Rotation, Translation, Shear, Perspective}\n",
    "   \n",
    "   x : step_length\n",
    "   \n",
    "   set_to_test : the array of pertubation to test on. \n",
    "                 Scaling ranges from 0 to a positive number.\n",
    "                 Perspective ranges from 56-max to 28+max\n",
    "                 Others range from -max to +max\"\"\"\n",
    "\n",
    "base = model.evaluate(train_data.reshape(-1,28,28,1),keras.utils.to_categorical(train_labels,10),verbose=0)[1]\n",
    "res = []\n",
    "points = []\n",
    "epsilon = 0.1\n",
    "print(\"Base Accuracy is \",base)\n",
    "\n",
    "\"\"\"Make sure to change these three variables appropriately\"\"\"\n",
    "name = \"Rotation\"\n",
    "max_perturbation = 90\n",
    "x = 10\n",
    "\n",
    "set_to_test = []\n",
    "if name == \"Scaling\":\n",
    "    set_to_test = np.arange(2-max_perturbation,max_perturbation+x,x)\n",
    "    points = [1]\n",
    "elif name == \"Perspective\":\n",
    "    set_to_test = np.arange(56-max_perturbation,max_perturbation+x,x)\n",
    "    points = [28]\n",
    "else:\n",
    "    set_to_test = np.arange(-max_perturbation,max_perturbation+x,x)\n",
    "    points = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:52:44.549976Z",
     "start_time": "2019-06-22T07:51:41.675278Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"The main loop. It continues til the model has >= accuracy than threshold on all pertubations in range\"\"\"\n",
    "\n",
    "while(True):\n",
    "    i,r = evaluate(model,base,train,name,set_to_test)\n",
    "    if (i > max_perturbation):\n",
    "        break\n",
    "    res.append(r)\n",
    "    points.append(i)\n",
    "    model= train_model(name,train,points)\n",
    "    print(\"New model created\")\n",
    "print(\"Model is robust\")\n",
    "points = np.array(points).round(decimals=2)\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:52:44.565507Z",
     "start_time": "2019-06-22T07:51:36.659Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test the robust model on test data over same pertubation range. Vertical lines show the training points\"\"\"\n",
    "r = evaluate(model,base,test,name,set_to_test)[1]\n",
    "plt.xlabel(name,fontsize = 18)\n",
    "plt.ylim(0,1.1)\n",
    "for i in points:\n",
    "    plt.axvline(i,c='red',linewidth=0.5)\n",
    "plt.ylabel(\"Accuracy\",fontsize = 18)\n",
    "plt.plot(r[:,0],r[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T07:51:30.377610Z",
     "start_time": "2019-06-22T07:51:28.044Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Save the model, results array and array of points\"\"\"\n",
    "model.save(\"MNIST_\" + name +\".h5\")\n",
    "np.save(\"MNIST_\" + name +\"_res.npy\",res)\n",
    "np.save(\"MNIST_\"+ name +\"_points.npy\",points)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
