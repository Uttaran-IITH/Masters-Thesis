{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T06:18:00.054265Z",
     "start_time": "2019-06-23T06:18:00.042611Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import sys\n",
    "import Structural_Perturbations as SP\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T06:18:00.721174Z",
     "start_time": "2019-06-23T06:18:00.263610Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\"\"\"Specifies batch size, number of classes in data and number of epochs\"\"\"\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "\"\"\"input image dimensions\"\"\" \n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\"\"\"Load/Download Dataset\"\"\"\n",
    "from keras.datasets import mnist\n",
    "train_data,train_labels,eval_data,eval_labels = SP.load('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T06:18:00.787562Z",
     "start_time": "2019-06-23T06:18:00.759187Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Defines architecture of the model. We use a 2 conv-layer followed by a fully-connected layer with \n",
    "   max-pooling and dropout in between layers. Loss is categorical cross-entropy and optimiser used is Adam\"\"\"\n",
    "def new_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            32, kernel_size=(3, 3), activation='relu',\n",
    "            input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\"\"\"Evaluates a given model over a range of perturbation\n",
    "   Local Variables : \n",
    "   \n",
    "   res : stores the perturbation and accuracy of the model on that pertubation\n",
    "   model : the loaded model\n",
    "   base : baseline accuracy of the model\n",
    "   name : name of the perturbation\n",
    "   alpha : the array of perturbation to check\n",
    "   d : the original unperturbed dataset\"\"\"\n",
    "def evaluate(model, base, d, name, alpha):\n",
    "    global epsilon\n",
    "    print(\"Number of uncovered points\", alpha.shape)\n",
    "    res = []\n",
    "    for i in alpha:\n",
    "        data = np.copy(d)\n",
    "        data = SP.Transform(name, data, i)\n",
    "        labels = data[:, -1]\n",
    "        labels = keras.utils.to_categorical(labels, 10)\n",
    "        data = data[:, 0:784]\n",
    "        data = data.reshape(-1, 28, 28, 1)\n",
    "        m1 = model.evaluate(\n",
    "            data, labels, verbose=0, batch_size=2048)[1]\n",
    "        res.append([i, m1])\n",
    "    res = np.array(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "\"\"\"Perturbs training dataset and trains a given model on a perturbed dataset. Global variable sym denotes\n",
    "    symmetric/asymmetric training method. If sym=1, symmetric training, hence append symmetric points.\n",
    "    Returns model\"\"\"\n",
    "def train_model(name, d, alpha):\n",
    "    global sym\n",
    "    data = np.copy(d)\n",
    "    if sym==1:\n",
    "        if name == 'Perspective':\n",
    "            alpha.append(56-alpha[-1])\n",
    "        elif name == \"Scaling\":\n",
    "            alpha.append(2-alpha[-1])\n",
    "        else:\n",
    "            alpha.append(-alpha[-1])\n",
    "    print(\"To be trained on \", alpha)\n",
    "    for i in alpha:\n",
    "        if i != alpha[0]:\n",
    "            perturbed_data = SP.Transform(name, d, i)\n",
    "            data = np.concatenate((data, perturbed_data))\n",
    "    model = new_model()\n",
    "    labels = data[:, -1]\n",
    "    labels = keras.utils.to_categorical(labels, 10)\n",
    "    data = data[:, 0:784].reshape(-1, 28, 28, 1)\n",
    "    model.fit(data, labels, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "    return model\n",
    "\n",
    "\"\"\"Loads data and stacks the labels as a column of data. This is required for multiprocessing.\"\"\"\n",
    "def load_data():\n",
    "    train_data, train_labels, eval_data, eval_labels = SP.load('mnist')\n",
    "    train_data = train_data.reshape(-1, 784)\n",
    "    train_labels = train_labels.reshape(-1, 1)\n",
    "    train = np.hstack((train_data, train_labels))\n",
    "    eval_data = eval_data.reshape(-1, 784)\n",
    "    eval_labels = eval_labels.reshape(-1, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    test = np.hstack((eval_data, eval_labels))\n",
    "    return (train, test, input_shape)\n",
    "\n",
    "\"\"\"Finds the centrepoint given an array of [perturbation,accuracy]\"\"\"\n",
    "def centerpoint(res):\n",
    "    res = np.array(res)\n",
    "    res = res[np.lexsort(np.fliplr(res).T)]\n",
    "    m = np.where(res[:,1] == min(res[:,1]))\n",
    "    m = res[m]\n",
    "    return m[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T06:18:03.622002Z",
     "start_time": "2019-06-23T06:18:00.814708Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Loads the data and Vanilla model\"\"\"\n",
    "train,test,input_shape = load_data()\n",
    "model = load_model(\"MNIST_vanilla.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T06:18:08.520438Z",
     "start_time": "2019-06-23T06:18:03.657325Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Finds the baseline accuracy of the vanilla model.\n",
    "   Variables:\n",
    "   \n",
    "   res : Stores the results array of accurcy vs perturbation\n",
    "   \n",
    "   sym : 1 denotes symmetric training, 0 asymmetric training\n",
    "   \n",
    "   points : Initialize with initial (natural) pertubation.\n",
    "            Scaling : 1\n",
    "            Perspective : 28\n",
    "            Else : 0\n",
    "            Stores the points on which derivative was maximum and hence needs training.\n",
    "            \n",
    "   epsilon : Defines our threshold. 0.1 = 10% accuracy drop\n",
    "   \n",
    "   max_perturbation : Stores the maximum allowed perturbation\n",
    "   \n",
    "   name : Name of pertubration {Exposure, Scaling, Rotation, Translation, Shear, Perspective}\n",
    "   \n",
    "   x : step_length\n",
    "   \n",
    "   set_to_test : the array of pertubation to test on(uncovered points). \n",
    "                 Scaling ranges from 0 to a positive number.\n",
    "                 Perspective ranges from 56-max to 28+max\n",
    "                 Others range from -max to +max\"\"\"\n",
    "\n",
    "base = model.evaluate(train_data.reshape(-1,28,28,1),keras.utils.to_categorical(train_labels,10),verbose=0)[1]\n",
    "res = []\n",
    "points = []\n",
    "epsilon = 0.1\n",
    "print(\"Base Accuracy is \",base)\n",
    "\n",
    "\"\"\"Make sure to change these three variables appropriately\"\"\"\n",
    "name = \"Rotation\"\n",
    "max_perturbation = 90\n",
    "x = 10\n",
    "sym = 1\n",
    "\n",
    "set_to_test = []\n",
    "if name == \"Scaling\":\n",
    "    set_to_test = np.arange(2-max_perturbation,max_perturbation+x,x)\n",
    "    points = [1]\n",
    "elif name == \"Perspective\":\n",
    "    set_to_test = np.arange(56-max_perturbation,max_perturbation+x,x)\n",
    "    points = [28]\n",
    "else:\n",
    "    set_to_test = np.arange(-max_perturbation,max_perturbation+x,x)\n",
    "    points = [0]\n",
    "s = np.copy(set_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T06:30:25.187590Z",
     "start_time": "2019-06-23T06:18:08.539929Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"The main loop. It continues til the model has >= accuracy than threshold on all pertubations in range\"\"\"\n",
    "\n",
    "while(True):\n",
    "    r = evaluate(model,base,train,name,set_to_test)\n",
    "    if min(r[:,1]) < base-epsilon:\n",
    "         i = centerpoint(r)\n",
    "    else:\n",
    "        break\n",
    "    u = 0\n",
    "    res.append(r)\n",
    "    \"\"\"Delete covered points\"\"\"\n",
    "    while(u<r.shape[0]):\n",
    "        if r[u][1] > (base - epsilon):\n",
    "            r = np.delete(r,(u),axis=0)\n",
    "        else:\n",
    "            u+=1\n",
    "    set_to_test = r[:,0]\n",
    "    if i<=max_perturbation:\n",
    "        points.append(i)\n",
    "        print(points)\n",
    "        model= train_model(name,train,points)\n",
    "        print(\"New model created\")\n",
    "print(\"Model is robust\")\n",
    "points = np.array(points).round(decimals=2)\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T06:33:29.441968Z",
     "start_time": "2019-06-23T06:33:13.741867Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test the robust model on test data over same pertubation range. Vertical lines show the training points\"\"\"\n",
    "r = evaluate(model,base,test,name,s)\n",
    "plt.xlabel(name,fontsize = 18)\n",
    "plt.ylim(0,1.1)\n",
    "for i in points:\n",
    "    plt.axvline(i,c='red',linewidth=0.5)\n",
    "plt.ylabel(\"Accuracy\",fontsize = 18)\n",
    "plt.plot(r[:,0],r[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Save the model, results array and array of points\"\"\"\n",
    "model.save(\"MNIST_\" + name +\".h5\")\n",
    "np.save(\"MNIST_\" + name +\"_res.npy\",res)\n",
    "np.save(\"MNIST_\"+ name +\"_points.npy\",points)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
